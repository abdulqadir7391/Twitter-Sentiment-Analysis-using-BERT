{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e0e4b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e69c4ac6",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9c70cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Language Courses Videos\\Machine Learning\\Complete Data Science, Machine Learning, Deep Learning, NLP Bootcamp 2024-10\\python\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tweepy\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e316a6",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Twitter API setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06cff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAFXk4AEAAAAA40%2B14zrsFGOzNZQeV%2Bv1%2FTtwxXg%3DRwENnDKJPI4msY0vZdIJG7q8ZeZjWtMIoELPsjbIW5kK8yC8lG\"\n",
    "  # <-- replace with your token\n",
    "\n",
    "if not BEARER_TOKEN:\n",
    "    raise ValueError(\"Bearer token not found. Please set TWITTER_BEARER_TOKEN environment variable.\")\n",
    "  \n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d37156",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f70cb94",
   "metadata": {},
   "source": [
    "Cell 2: Import libraries and load Bearer Token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33afc87",
   "metadata": {},
   "source": [
    "# 2. Define Tweet Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68f8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_tweet(text):\n",
    "    text = re.sub(r'http\\S+|@\\S+|#\\S+', '', text)  # remove urls, mentions, hashtags\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', '', text)    # remove special characters\n",
    "    return text.lower().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80c2bf",
   "metadata": {},
   "source": [
    "# 3. Load BERT model & Sentiment model classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2204074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "sentiment_classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    result = sentiment_classifier(text)[0]\n",
    "    label = result['label']   # e.g. \"4 stars\"\n",
    "    score = result['score']\n",
    "\n",
    "    if \"1\" in label or \"2\" in label:\n",
    "        sentiment = \"Negative\"\n",
    "    elif \"3\" in label:\n",
    "        sentiment = \"Neutral\"\n",
    "    else:\n",
    "        sentiment = \"Positive\"\n",
    "\n",
    "    return sentiment, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb66d0",
   "metadata": {},
   "source": [
    "# 4. Setup MongoDB connection and save function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92382d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = mongo_client.twitter_sentiment\n",
    "tweets_collection = db.tweets\n",
    "\n",
    "def save_to_db(tweet, sentiment, score):\n",
    "    doc = {\n",
    "        'tweet_id': tweet.id,\n",
    "        'text': tweet.text,\n",
    "        'clean_text': preprocess_tweet(tweet.text),\n",
    "        'sentiment': sentiment,\n",
    "        'score': score,\n",
    "        'created_at': tweet.created_at,\n",
    "        'lang': tweet.lang,\n",
    "        'inserted_at': datetime.utcnow()\n",
    "    }\n",
    "    tweets_collection.insert_one(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d009e778",
   "metadata": {},
   "source": [
    "# 5. Fetch tweets (instead of streaming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7c1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"#AI lang:en -is:retweet\"  # hashtag + English + no retweets\n",
    "tweets = client.search_recent_tweets(query=query,\n",
    "                                     tweet_fields=[\"created_at\", \"lang\"],\n",
    "                                     max_results=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae9ac9e",
   "metadata": {},
   "source": [
    "# 6. Process and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70f6bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_23852\\485228897.py:14: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  'inserted_at': datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-16 09:59:47+00:00] Positive (0.53): Our datasets are a massive collection of high-quality, multimodal data, including: Text, Multimodal, Global, and Logical Reasoning.\n",
      "#AI #data #SupplyChain https://t.co/U8cAOx01Mi\n",
      "[2025-09-16 09:59:42+00:00] Negative (0.30): ðŸš€ AI made headlines today:\n",
      "\n",
      "ðŸš— NVIDIAâ€™s new AIBOX puts large AI models inside cars.\n",
      "\n",
      "ðŸ‘“ Metaâ€™s AI glasses face supply chain risks tied to China.\n",
      "\n",
      "ðŸŒ https://t.co/9X1XmtyFYv &amp; Expedia brace for disruption from AI travel agents.\n",
      "\n",
      "#AI #Meta #Travel #Business #Nvidia https://t.co/GPzVFJmswZ\n",
      "[2025-09-16 09:59:39+00:00] Negative (0.45): I talk about how much fewer revenues are coming out of the #AI system (and no profits) than investments are going in. The pop is getting close particularly with the unethical lease backs of Nvidia chips.  https://t.co/8YhJl3FuhB\n",
      "[2025-09-16 09:59:35+00:00] Positive (0.49): ðŸ¡ Buying a home just got smarter ðŸ”— reAlpha expands Claire, an AI concierge that captures your budget, lifestyle &amp; location, then guides you step-by-step â€” from searching to closing, even with commission rebates. #HomeBuying #AI #FinTech $AIRE  \n",
      "\n",
      "https://t.co/3zpTeOQjEu\n",
      "[2025-09-16 09:59:34+00:00] Negative (0.62): Dear @sundarpichai @Google @GoogleAI,  \n",
      "Local police warned that Gemini AI photo editing can misuse peopleâ€™s images &amp; make them viral for bad purposes.  \n",
      "Please investigate &amp; give clear safety guidance.  \n",
      "Public safety is at risk.  \n",
      "#AI #Privacy\n",
      "[2025-09-16 09:59:33+00:00] Negative (0.25): .@linera_io Blockchains werenâ€™t built for millions of AI agents. âš¡\n",
      "Linera is the next-gen chain for the real-time, agentic Web.\n",
      "#Linera #AI #Web3\n",
      "[2025-09-16 09:59:13+00:00] Negative (0.57): A.i is cheating\n",
      "#perplexity #gemini #chatgpt #deepseek #claude #AI https://t.co/Lm63xeGleq\n",
      "[2025-09-16 09:59:12+00:00] Positive (0.54): The Energy Management System market is evolvingâ€”despite costs and challenges, EMS is emerging as a cornerstone for efficiency, resilience, and global sustainability.\n",
      "\n",
      "Read More: https://t.co/rCYtqiWFlP\n",
      "\n",
      "#EnergyManagement #Sustainability #SmartCities #GreenTech #AI #IoT https://t.co/MgelN82Vs0\n",
      "[2025-09-16 09:59:11+00:00] Positive (0.42): \"An aggressive, volatile red dragon breathing fire with its sharp talons extended in attack, set against a turbulent stormy sky, with waves crashing fiercely against rugged cliffs.\"\n",
      "#AIArt #AI #chatgpt4 #dalle3 #OpenAi #AIFeelings https://t.co/iLpa6qk3bF\n",
      "[2025-09-16 09:59:11+00:00] Positive (0.59): Success of $DMTR farming #AI insights has lead its growth from 1.5 million farms to 6 million under contract.Fourfold in size since January.600k is expected from October going forward from $DMTR buybacks.\n",
      "Loving the journey &amp; thankful for recent successes.Congrats teamðŸ”¥ðŸ”¥ \n",
      "$BTC https://t.co/A3oTn1kHdM https://t.co/y49mnGVEcw\n"
     ]
    }
   ],
   "source": [
    "if tweets.data:\n",
    "    for tweet in tweets.data:\n",
    "        clean = preprocess_tweet(tweet.text)\n",
    "        sentiment, score = classify_sentiment(clean)\n",
    "        save_to_db(tweet, sentiment, score)\n",
    "        print(f\"[{tweet.created_at}] {sentiment} ({score:.2f}): {tweet.text}\")\n",
    "else:\n",
    "    print(\"No tweets found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f0036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5e48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40960fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a75f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9037315",
   "metadata": {},
   "source": [
    "Cell 7: Define tweet streaming client class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f31340",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStream(tweepy.StreamingClient):\n",
    "    def on_tweet(self, tweet):\n",
    "        clean = preprocess_tweet(tweet.text)\n",
    "        sentiment, score = classify_sentiment(clean)\n",
    "        save_to_db(tweet, sentiment, score)\n",
    "        print(f\"[{tweet.created_at}] {sentiment} ({score:.2f}): {tweet.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd069731",
   "metadata": {},
   "source": [
    "Cell 8: Start streaming tweets for hashtag #AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = MyStream(BEARER_TOKEN)\n",
    "\n",
    "# Delete existing rules to avoid duplicates\n",
    "rules = stream.get_rules()\n",
    "if rules.data:\n",
    "    stream.delete_rules([rule.id for rule in rules.data])\n",
    "\n",
    "# Add hashtag rule\n",
    "stream.add_rules(tweepy.StreamRule(\"#AI\"))\n",
    "\n",
    "# Start streaming; specify tweet fields\n",
    "stream.filter(tweet_fields=[\"created_at\", \"lang\", \"geo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48e4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
